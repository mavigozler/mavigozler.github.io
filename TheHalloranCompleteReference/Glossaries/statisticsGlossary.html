<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
        "http://www.w3.org/TR/REC-html40/loose.dtd">
<!-- Take note of the doctype convention...remove 'Transitional' with
     no space before //EN and change 'loose' to 'strict' -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="Author" content="Nobody">
<title>Glossary of Statistics</title>
<link type="text/css" href="stats.css" rel="stylesheet">
<style type="text/css">
	DT {
   	font : bold 100% Verdana,Tahoma,Helvetica,Arial,sans-serif;
      color : green;
      text-decoration: underline;
   }
   .detail {
   	background-color : #f8f8ff;
      border : 1px solid #800080;
      padding: 1em;
      margin : 1em;
      font-size : 83%;
   }
</style>
</head>

<body>
<p id="title">
Glossary on Statistics

<dl>
 <dt><a name="df">degrees of freedom</a>
 <dd>One of the better definitions
     <a href="http://homepages.enterprise.net/rtj/Whichstats6.html">found</a>
     on the Internet is this one:<br>
     the degrees of freedom of an estimate is equal to the number
     of independent scores that go into the estimate minus the
     number of parameters estimated as intermediate steps in
     the estimation of the parameter itself
   <div class="detail">
     For example, in calculating the variance/standard deviation,
     <i>n</i> &#150; 1 degrees of freedom are said to be necessary in
     calculating the variance, since the mean itself can be used to
     learn the <i>n</i>th value.
     <p>
     Or how about one-way ANOVA?  Two components of the total variance
     are determined in this technique:  the sum of the square of
     the differences of the mean of each treatment and the overall
     mean is an estimate of the variance <i>between</i> treatments (SSTR),
     and the sum of the square of the differences of values and the mean
     <i>within</i> the treatment group is an estimate of the typical error
     variance within a group (SSE).  The so-called <i>mean</i>
     of these summed squared differences is then calculated by dividing
     by their appropriate degrees of freedom.  For the between-treatment
     analysis, if there are <i>k</i> treatments being analyzed, then
     the degrees of freedom is <i>k</i> &#150; 1 for calculating
     the mean (MSTR), or SSTR/(<i>k</i> &#150; 1).  For calculating
     the mean error variance (MSE), this requires that one only need
     the total number of observations for all data in all treatment
     groups (call it <i>n</i>) less the information one gets from having
     estimates of the overall mean and the means of each of the
     treatment groups.  This ends up being (<i>n</i> &#150; 1) &#150;
     (<i>k</i> &#150; 1) = <i>n &#150; k</i>.
     So MSE = SSE / (<i>n &#150; k</i>).
	</div>
</dl>
<dl>
 <dt><a name="type1">Type I error</a>
 <dd>The error in rejecting a true null hypothesis (<i>H</i><sub>0</sub>).
   This is also called &alpha; (alpha).  The level of significance
   &alpha; represents the probability (area under the curve) that
   that an absolute value of a statistical measure of the data
   equals or exceeds the absolute value of a critical limit of the
   statistical measure.  For example, the usual level of significance
   &alpha; = 0.05, and if the statistical measure is Student's <i>t</i>,
   there is a particular <i>t</i> value, the <b>critical</b> <i>t</i>,
   which represents the limit of the <i>t</i> distribution in which the
   measure of the area of the tail of the distribution is equal to &alpha;.
</dl>
<dl>
 <dt><a name="type2">Type II error</a>
 <dd>The error in accepting a false null hypothesis (<i>H</i><sub>0</sub>).
</dl>

</body>
</html>
