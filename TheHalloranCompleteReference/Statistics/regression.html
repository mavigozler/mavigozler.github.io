<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
        "http://www.w3.org/TR/REC-html40/loose.dtd">
<!-- Take note of the doctype convention...remove 'Transitional' with
     no space before //EN and change 'loose' to 'strict' -->
<html lang="en">
<HEAD>
<META http-equiv="Content-Type" content="text/html; charset=utf-8">
<META name="Author" content="Nobody">
<TITLE>Linear Regression</TITLE>
<STYLE>
	BODY { margin : 0 5% ; background-color : #f8fff8 ; }
    #title {
    	text-align : center ;
        font : bold 150% Tahoma,Arial,sans-serif ;
        color : blue;
        margin : 2em 0 ;
    }
    H1 { font : bold 130% "Times New Roman",serif ;
    		margin : 1.5em 0 1em 0 ;
            color : #2222bb;
            border-top : 10px solid #bbbbbb ; }
    H2 { font : bold 110% Tahoma,Arial,sans-serif ;
    		margin : 1em 1em 0.5em 1em ;
            color : #884444 ;
     }
    H3 { font : bold 110% "Times New Roman",serif ; margin : 1em 1.5em ;
          font-style: oblique ;}
    H4 { font : bold 100% Arial,sans-serif ; margin : 0.5em 2em ;}
    .bord { border-bottom : 1px solid black ; }
    .eqn {
    	font : bold 120% Tahoma,Arial,sans-serif;
        text-align : center ;
    }
    IMG { margin : 1em ; vertical-align : middle; }
</STYLE>
</HEAD>

<BODY>
<p id="title">
Linear Regression
<p>
You should already have a good understanding of basic statistical
concepts, such as characterizing a univariate data set by its mean
and standard deviation and variance, before reading further.
After reading this, you can also proceed to the discussion of
characterizing bivariate data sets (where both <i>x</i> and <i>y</i>
data sets vary) using the <a href="corrcoeff.html">correlation</a>
model.
<h1>Basic Concepts</h1>
Suppose that one particular parameter is understood to <i>depend</i>
on another particular parameter.  In medicine, of which there are
many examples like these, suppose that the build up of hard plaque
substance on the inside of the aorta (also called &#147;hardening&#148;)
is related to the long-term consumption of a diet high in saturated
fats.  Mathematically, an expression can be created where a
<i>dependent variable</i>, a reasonable measure of the build up
of plaque in the aorta, is related to, or equated to, an
<i>independent variable</i>.
<p>
<img style="float:right;" src="regression/linreg1.gif"
   alt="scatter plot of example data">
Suppose a plot of all the data is
done, with the dependent variable plotted on the ordinate or vertical,
that is, <b><i>y</i></b> axis, and the independent variable plotted
on the abscissa or horizontal, that is, <b><i>x</i></b> axis.  The plot
may look something like the one in the figure at the right.
As more data is accumulated an plotted, one begins to observe a pattern
of some kind.  If the dependent variable varies <i>directly</i> with
the independent variable, a <i>linear</i> relationship is observable.
According the principles of Cartesian analytical geometry, a line
a two-dimensional coordinate system such as the plot of the data
fits a well-known model equation:
<p align="center">
<i>y = a + bx</i>&nbsp;&nbsp;[1]
<p>
where the coefficient <i>a</i> is the value of <i>y</i> when
<i>x</i> has the value
of zero (this is usually called the &#147;<i>y</i> intercept&#148; as it is
the point on the line where it &#147;intercepts&#148; the <i>y</i> axis),
and <i>b</i> is the relationship for how <i>y</i> changes with <i>x</i>, or
&Delta;<i>y</i>/&Delta;<i>x</i> (usually called the &#147;slope&#148;
of the line).
<p>
In statistics, data which can be described in a linear fashion also
uses this equation, with a modificiation:
<p align="center">
<i>y<sub>i</sub></i> = &beta;<sub>0</sub> + &beta;<sub>1</sub><i>x<sub>i</sub></i> +
&xi;<i><sub>i</sub></i>&nbsp;&nbsp;[2]
<p>
&beta;<sub>0</sub> and &beta;<sub>1</sub> are the same as <i>a</i> and
<i>b</i>, respectively, in <b>[1]</b>, and statisticians may refer to
&beta;<sub>0</sub> as the <i>regression constant</i> and
&beta;<sub>1</sub> as the <i>regression coefficient</i>.
&xi;<i><sub>i</sub></i> is a <i>random error</i> term associated with
each point.
<h1>Simple Linear Regression</h1>
The equations above show that a certain parameter, a dependent variable,
depends upon <em>only</em> one other parameter, an independent variable.
It is possible that a single parameter can depend on more than one
parameter, that is, a dependent variable related to multiple independent
variables.  One can use the techniques of <a href="#multreg"><b>multiple
regression</b></a> to examine the nature of that kind of relationship.
But when there is only one variable that influences the matter (or can
be assumed to do so), one uses <b>simple linear regression</b> to
understand the nature of the influence.
<p>
Before using simple linear regression, there is a checklist of assumptions
that need to be met if the use of this technique is to have any value
in analyzing the data set:
<ul>
<li>The scale by which any of the variables are measured must be
such that a regression analysis can describe the data properly.  For
data measured on a continuous scale of real or integer numbers, this is
usually no problem.  Most measurements of natural phenomenon are amenable
to such scaling, but even approaches such as transformations or
assigning numerical values to nominal categories can make data amenable
to regression analysis.
<li>The variable that has been called &#147;independent&#148; (the
<i>x<sub>i</sub></i> variable) up to this point may consist of
values which have been chosen randomly <em>or</em> in a pre-determined way.
Take the example above.  When the people are selected for participation
in the aorta hardening-diet study, both the extent of the aortic plaque
deposition or formation and the amount of saturated fat in the diet are
unknown and must be measured.  Alternatively, a medical researcher may
want to limit selection of patients to those with a pre-determined
amount of dietary saturated fat, such as 5%, 15%, 25%, and 35% by weight
of fat to total food consumed.
<li>
The independent variable, <i>x</i>, must be measured without any
associated error.  In truth, many measurements of the independent
variable are not made without error, and there are technqiues that
make the analysis more complicated but which can propagate the error
in the final report.  For practical purposes, it is reasonable to
assume that the error in the independent variable is negligible
and does not invalidate any analysis in the assumption.
<li>The dependent variable (<i>y</i>) must be entirely random, and not
pre-determined.  That is, it would be inappropriate for the researcher
to exclude certain data, especially if it is to fit a bias.  (That is
not to say that no collected data is excludable, but it must be for
other factors than the expectations of what the dependent variable
is to show.)
<li>
<img src="regression/simpreg.gif" alt="plot showing normally distributed
data of y values for each x value" style="float:right;">
The dependent variable <i>y</i> for each value at <i>x</i> is
part of a <em>normally distributed</em> set of <i>y</i> values at each
value <i>x</i>.  Because they are normally
distributed, a mean value and standard deviation can be determined.
In the regression analysis, the mean value will become the
<i>predicted y</i> value upon which the fitted line will pass.
The figure at the right shows a set of normally distributed values
of the dependent variable for each measure of the independent variables,
and the red line passes through the mean of the subpopulation of <i>y</i>
values at each point <i>x</i>
<li>
To make inferences about the data, the variances for the set of
<i>y</i> values at each value <i>x</i> must be (approximately) equal
(note that this is also a requirement for group variances in ANOVA).
</ul>
<h2>Least squares analysis</h2>
There are variety of techniques for fitting a line to the data.  One
could reasonably do it &#147;by eye&#148; and probably come up with
a good line.
<p>
The method most used however is the mathematical approach of estimating
a line that minimizes the differences of all original data <i>y</i> values
from a single <i>y</i> (&#147;predicted&#148;) value that forms a part
of the line.  This is the <b>least squares</b> approach.  The regression
values for
<p align="center">
<i>y<sub>r</sub></i> = <i>b</i><sub>0</sub> +
              <i>b</i><sub>1</sub><i>x<sub>i</sub></i>
<p>
are:
<p style="color:red;font:bold 100% Verdana,Helvetica,Arial,sans-serif;">
  Text ends here...this article remains to be completed
<p>The source used for the information presented above:
Wayne W. Daniel, <i>Introductory Statistics with Applications</i>,
Boston: Houghton Mifflin, 1977.
</BODY>
</HTML>
